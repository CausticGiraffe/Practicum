{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Cervix Cancer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dependancies \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns \n",
    "import cv2\n",
    "import skimage.io as io\n",
    "import keras\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls \n",
    "py.init_notebook_mode(connected=True)\n",
    "import random \n",
    "import shutil\n",
    "\n",
    "from skimage.io import imread, imshow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Reshape\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras import optimizers\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"/home/kray/Practicum/train\"]).decode(\"utf8\"))\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.utils import shuffle\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of images for each cervix type in train with plot.\n",
    "# Code modified from Poonam Ligade, Intel cervical cancer EDA https://www.kaggle.com/poonaml/intel-cervical-cancer-eda \n",
    "sub_folders = check_output([\"ls\", \"/home/kray/Practicum/train\"]).decode(\"utf8\").strip().split('\\n')\n",
    "count_dict = {}\n",
    "for sub_folder in sub_folders:\n",
    "    num_of_files = len(check_output([\"ls\", \"/home/kray/Practicum/train/\"+sub_folder]).decode(\"utf8\").strip().split('\\n'))\n",
    "    print(\"{0} photos of cervix type {1}\".format(num_of_files, sub_folder))\n",
    "                            \n",
    "    count_dict[sub_folder] = num_of_files\n",
    "                            \n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(list(count_dict.keys()), list(count_dict.values()), alpha = 0.8)\n",
    "plt.xlabel('Cervix types', fontsize = 11)\n",
    "plt.ylabel('Number of images in train', fontsize = 11)\n",
    "plt.title('train dataset')\n",
    "                            \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Number of test images. \n",
    "num_test_files = len(check_output([\"ls\", \"/home/kray/Practicum/test/\"]).decode(\"utf8\").strip().split('\\n'))\n",
    "print(\"Number of test images present:\", num_test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (12, 8))\n",
    "\n",
    "i = 1\n",
    "for t in \"/home/kray/Practicum/train\"['type'].unique():\n",
    "    ax = fig.add_subplot(1,3,i)\n",
    "    i +=1\n",
    "    f = \"/home/kray/Practicum/train\"[\"/home/kray/Practicum/train\"['type'] == t]['imagepath'].values[0]\n",
    "    plt.imshow(plt.imread(f))\n",
    "    plt.title('sample for cervix {}'.format(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Image size distribution, barplot. \n",
    "# Code modified from Poonam Ligade, Intel cervical cancer EDA https://www.kaggle.com/poonaml/intel-cervical-cancer-eda \n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "#sns.barplot(list(different_file_sizes.values()), list(different_file_sizes.keys()), alpha = 0.8)\n",
    "import pprint\n",
    "pprint.pprint(different_file_sizes)\n",
    "#plt.ylabel('Image size', fontsize = 11)plt.xlabel('Number of images in train', fontsize = 11)\n",
    "plt.title(\"Image sizes present in train dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split data into training and validation sets, keeping file organization. \n",
    "allFiles = glob.glob('/home/kray/Practicum/train/*/*')\n",
    "\n",
    "split_point = int(round(0.7*len(allFiles)))\n",
    "random.shuffle(allFiles)\n",
    "\n",
    "train_list = allFiles[:split_point]\n",
    "valid_list = allFiles[split_point:]\n",
    "print('Train images: {}'.format(len(train_list)))\n",
    "print('Validation images {}'. format(len(valid_list)))\n",
    "\n",
    "# Divy them into their own directories.\n",
    "train_data_path = '/home/kray/Practicum/train_data'\n",
    "validation_data_path = '/home/kray/Practicum/valid_data'\n",
    "if not os.path.exists(train_data_path):\n",
    "    os.makedirs(train_data_path)\n",
    "if not os.path.exists(validation_data_path):\n",
    "    os.makedirs(validation_data_path)\n",
    "\n",
    "for fpath in train_list:\n",
    "    basename = fpath.split('/')[-2:]\n",
    "    dest = '/'.join([train_data_path] +basename)\n",
    "    if not os.path.exists('/'.join(dest.split('/')[:-1])):\n",
    "        os.makedirs('/'.join(dest.split('/')[:-1]))\n",
    "    shutil.copyfile(fpath, '/'.join([train_data_path] +basename))\n",
    "for fpath in valid_list:\n",
    "    basename = fpath.split('/')[-2:]\n",
    "    dest = '/'.join([validation_data_path] +basename)\n",
    "    if not os.path.exists('/'.join(dest.split('/')[:-1])):\n",
    "        os.makedirs('/'.join(dest.split('/')[:-1]))    \n",
    "    shutil.copyfile(fpath, '/'.join([validation_data_path] +basename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K.set_image_dim_ordering('tf')\n",
    "\n",
    "# Create numpy array\n",
    "train_image_list = list()\n",
    "train_label_list = list()\n",
    "for image in train_list[:10]:\n",
    "    im = cv2.imread(image)\n",
    "    im_type = image.split('/')[-2]\n",
    "    train_label_list.append(im_type)\n",
    "    train_image_list.append(im)\n",
    "print (train_label_list)\n",
    "print(train_image_list)\n",
    "\n",
    "# Reshape\n",
    "train_list = train_list.reshape(train_list[0], 32, 32, 3).astype('float32')\n",
    "valid_list = Reshape(valid_list[0], 32, 32, 3).astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dimensions of images\n",
    "img_width, img_height = 255, 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_list,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        valid_list,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "nb_epoch = 5\n",
    "nb_train_samples = 1036\n",
    "nb_validation_samples = 444"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(\n",
    "        train_list,\n",
    "        samples_per_epoch = nb_train_samples,\n",
    "        nb_epoch = nb_epoch,\n",
    "        valid_list = valid_list,\n",
    "        nb_val_samples = nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# second CNN model\n",
    "# batch generator \n",
    "\n",
    "def batch_generator_train(files, batch_size):\n",
    "    number_of_batches = np.ceil(len(files)/batch_size)\n",
    "    counter = 0\n",
    "    random.shuffle(files)\n",
    "    while True:\n",
    "        batch_files = files[batch_size*counter:batch_size*(counter+1)]\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        for f in batch_files:\n",
    "            image = cv2.imread(f)\n",
    "            image = cv2.resize(image, conf['image_shape'])\n",
    "\n",
    "            train_label_list = f[20:21] # relies on path lengths that is hard coded below\n",
    "            if cancer_type == '1':\n",
    "                mask = [1, 0, 0]\n",
    "            elif cancer_type == '2':\n",
    "                mask = [0, 1, 0]\n",
    "            else:\n",
    "                mask = [0, 0, 1]\n",
    "\n",
    "            image_list.append(image)\n",
    "            mask_list.append(mask)\n",
    "        counter += 1\n",
    "        image_list = np.array(image_list)\n",
    "        mask_list = np.array(mask_list)\n",
    "\n",
    "        yield image_list, mask_list\n",
    "\n",
    "        if counter == number_of_batches:\n",
    "            random.shuffle(files)\n",
    "            counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# used to rescale the pixel values from [0, 255] to [0, 1] interval\n",
    "# Code modified from Siraj Raval, Intro to Deep Learning https://github.com/llSourcell/how_to_make_an_image_classifier/blob/master/demo.ipynb\n",
    "\n",
    "datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# automagically retrieve images and their classes for train and validation sets\n",
    "# Code modified from Siraj Raval, Intro to Deep Learning https://github.com/llSourcell/how_to_make_an_image_classifier/blob/master/demo.ipynb\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_list,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=16,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        validation_list,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Simple CNN model.\n",
    "# Code modified from libphy https://github.com/libphy/dldev/blob/master/MNIST-Keras.ipynb\n",
    "\n",
    "def simple_cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(img_width, img_height,3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation = 'relu'))\n",
    "    #model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    # Compile model\n",
    "    # Code modified from libphy https://github.com/libphy/dldev/blob/master/MNIST-Keras.ipynb\n",
    "\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics = ['accuracy']) \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "model = simple_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create numpy array\n",
    "train_image_list = list()\n",
    "train_label_list = list()\n",
    "for image in train_list[:10]:\n",
    "    im = cv2.imread(image)\n",
    "    im_type = image.split('/')[-2]\n",
    "    train_label_list.append(im_type)\n",
    "    train_image_list.append(im)\n",
    "print (train_label_list)\n",
    "print(train_image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(train_image_list, train_label_list, batch_size = 32, nb_epoch = 5, verbose = 1)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(train_data_path, validation_data_path, verbose = 0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('models/basic_cnn_1_epoch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evaluating on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Computing loss and accuracy \n",
    "model.evaluate_generator(validation_generator, nb_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data augmentation for improving model by applying random transformation to the train set. \n",
    "#reduces overfitting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create an ensembe with pre-trained models: VGG16, ResNet_V2, and Inception_V3, then fine tune the top layers of the pre-trained networks. \n",
    "https://gihub.com/tensorflow/models/blob/master/slim/README.md#Pretrained\n",
    "\n",
    "2. Experiment with more k-folds on the training images\n",
    "\n",
    "3. Explore bounding box annotations \n",
    "\n",
    "4. Train and test the improved model on the additional images and second relase images\n",
    "\n",
    "5. Incorrporate additional visualizations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
